{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoeeao0sr-2-"
      },
      "source": [
        "# Робота з Spark RDD\n",
        "\n",
        "## Найпопулярніші пари продуктів\n",
        "\n",
        "В якості датасету для завдання необхідно використати [Amazon Reviews](https://www.kaggle.com/snap/amazon-fine-food-reviews).\n",
        "\n",
        "> Для більш зручної розробки логіки в додатково в Класрумі є скорочений файл схожої структури `sample.csv`.\n",
        "\n",
        "Датасет має наступну структуру. Друга колонка - ідентифікатор продукту, третя - ідентифікатор юзера:\n",
        "\n",
        "```\n",
        "Id,ProductId,UserId,ProfileName,HelpfulnessNumerator,HelpfulnessDenominator,Score,Time,Summary,Text\n",
        "```\n",
        "\n",
        "Наприклад:\n",
        "\n",
        "| Id | ProductId | UserId | ProfileName | ...інші колонки |\n",
        "|----|-----------|--------|-------------|-----------------|\n",
        "| 1  | B1        | A2     | Patron      | ...             |\n",
        "\n",
        "### Опис завдання\n",
        "\n",
        "1. Зчитати скорочений або повний датасет як RDD. Після читання вирізати лише потрібні колонки: `UserId` та `ProductId`.\n",
        "2. Створити `RDD`, що містить пари (`tuple`) `UserId` та список всіх `ProductId` для всіх продуктів, які придбав цей юзер. В списку повинні бути лише **унікальні** продукти (`ProductId` для одного юзера не повинні повторюватись). Наприклад:\n",
        "\n",
        "```python\n",
        "(\"A1\", [\"B1\", \"B2\", \"B5\"])\n",
        "(\"A2\", [\"B1\", \"B3\", \"B5\"])\n",
        "...\n",
        "```\n",
        "\n",
        "3. Взявши списки продуктів для кожного юзера, отримати всі пари продуктів які він міг купувати разом. Для кожної такої пари створити `tuple` де першим елементом є пара, другим число `1`. Наприклад для попереднього списку:\n",
        "```python\n",
        "(\"B1,B2\", 1)\n",
        "(\"B1,B5\", 1)\n",
        "(\"B2,B5\", 1)\n",
        "(\"B1,B3\", 1)\n",
        "(\"B1,B5\", 1)\n",
        "(\"B3,B5\", 1)\n",
        "...\n",
        "```\n",
        "\n",
        "> Два продукти вважаються придбаними разом, якщо вони обидва з’являються у списку, який ви отримали на попередньому кроці.\n",
        "\n",
        "4. Підрахувати кількість всіх пар продуктів, відсортувати їх за кількістю від найбільшої до найменшої.\n",
        "5. Взяти лише перші `10` пар продуктів та їх кількість. Наприклад:\n",
        "```python\n",
        "(\"B1,B5\", 23495)\n",
        "(\"B2,B5\", 3340)\n",
        "(\"B3,B5\", 217)\n",
        "...\n",
        "```\n",
        "6. Зберегти результат в текстовий файл."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLMh0X3or-3A"
      },
      "source": [
        "## Конфігурація\n",
        "\n",
        "- `number_cores`: Кількість ядер, виділених під Spark\n",
        "- `memory_gb`: Обʼєм оперативної памʼяті, виділеної під Spark (в Гб)\n",
        "- `is_full_dataset`: Читати повний чи скорочений датасет."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOo-CUDer-3A"
      },
      "outputs": [],
      "source": [
        "number_cores = 2\n",
        "memory_gb = 4\n",
        "is_full_dataset = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJNOhAk8r-3B"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "import os\n",
        "\n",
        "number_cores = 2\n",
        "memory_gb = 4\n",
        "conf = (\n",
        "    SparkConf()\n",
        "        .setAppName(\"Spark Rdd Task\")\n",
        "        .setMaster(f'local[{number_cores}]')\n",
        "        .set('spark.driver.memory', f'{memory_gb}g')\n",
        ")\n",
        "\n",
        "sc = SparkContext(conf=conf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeYRX6uKr-3B"
      },
      "source": [
        "## Рішення"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2MavSRgr-3C"
      },
      "outputs": [],
      "source": [
        "if is_full_dataset:\n",
        "    if not os.path.exists('Reviews.csv'):\n",
        "        sc.stop()\n",
        "        raise Exception(\"\"\"\n",
        "            Download the 'Reviews.csv' file from https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews\n",
        "            and put it in 'input' folder\n",
        "        \"\"\")\n",
        "    else:\n",
        "        inputRdd = sc.textFile(\"Reviews.csv\")\n",
        "else:\n",
        "    inputRdd = sc.textFile(\"sample.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GQQNxjur-3C"
      },
      "outputs": [],
      "source": [
        "# Видалення рядку заголовку\n",
        "filteredInput = inputRdd.filter(lambda line: line.startswith(\"Id,\") == False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QtvOENDr-3C"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "\n",
        "user_product_pairs = filteredInput.map(lambda line: line.split(\",\")).map(lambda x: (x[2], x[1]))\n",
        "user_products = user_product_pairs.groupByKey().mapValues(set)\n",
        "user_product_pairs_combinations = user_products.flatMap(lambda x: [(pair, 1) for pair in combinations(sorted(x[1]), 2)])\n",
        "product_pair_counts = user_product_pairs_combinations.reduceByKey(lambda x, y: x + y)\n",
        "sorted_product_pair_counts = product_pair_counts.sortBy(lambda x: x[1], ascending=False)\n",
        "top_10_product_pairs = sorted_product_pair_counts.take(10)\n",
        "sc.parallelize(top_10_product_pairs).coalesce(1).saveAsTextFile(\"output\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ITgMZ6Yr-3C"
      },
      "source": [
        "## Зупинка Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKdZZN8gr-3D"
      },
      "outputs": [],
      "source": [
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}